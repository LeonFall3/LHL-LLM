{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\LHL\\LHL-LLM\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "ds_train = pd.read_pickle('pickles/ds_train.pkl')\n",
    "ds_test = pd.read_pickle('pickles/ds_test.pkl')\n",
    "\n",
    "\n",
    "# Rename the columns\n",
    "ds_train = ds_train.drop(columns=['text'])\n",
    "ds_test = ds_test.drop(columns=['text'])\n",
    "ds_train = ds_train.rename(columns={'label':'og_label', 'simple_topic':'label', 'no_stopword':'text'})\n",
    "ds_test = ds_test.rename(columns={'label':'og_label', 'simple_topic':'label', 'no_stopword':'text'})\n",
    "\n",
    "# Create new datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "new_train = Dataset.from_pandas(ds_train[['label','text']])\n",
    "new_test = Dataset.from_pandas(ds_test[['label','text']])\n",
    "\n",
    "# Create a DatasetDict\n",
    "new_ds = DatasetDict({\n",
    "    'train': new_train,\n",
    "    'test': new_test\n",
    "})\n",
    "\n",
    "# Save the new datasets to disk\n",
    "# new_ds.save_to_disk('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>3</td>\n",
       "      <td>i was wondering if anyone out there could enli...</td>\n",
       "      <td>wondering anyone could enlighten car saw day 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1</td>\n",
       "      <td>a fair number of brave souls who upgraded thei...</td>\n",
       "      <td>fair number brave souls upgraded si clock osci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1</td>\n",
       "      <td>well folks my mac plus finally gave up the gho...</td>\n",
       "      <td>well folks mac plus finally gave ghost weekend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>do you have weiteks addressphone number  id l...</td>\n",
       "      <td>weiteks addressphone number id like get inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>4</td>\n",
       "      <td>from article  by  tom a baker   my understandi...</td>\n",
       "      <td>article tom baker understanding expected error...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>4</td>\n",
       "      <td>dn from  david nye dn a neurology dn consultat...</td>\n",
       "      <td>dn david nye dn neurology dn consultation chea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1</td>\n",
       "      <td>i have a very old mac 512k and a mac plus both...</td>\n",
       "      <td>old mac 512k mac plus problem screens blank so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>1</td>\n",
       "      <td>i just installed a dx266 cpu in a clone mother...</td>\n",
       "      <td>installed dx266 cpu clone motherboard tried mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>wouldnt this require a hypersphere  in 3space...</td>\n",
       "      <td>wouldnt require hypersphere 3space 4 points sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>3</td>\n",
       "      <td>stolen from pasadena between 430 and 630 pm on...</td>\n",
       "      <td>stolen pasadena 430 630 pm 415 blue white hond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       og_label                label_text  label  \\\n",
       "0             7                 rec.autos      3   \n",
       "1             4     comp.sys.mac.hardware      1   \n",
       "2             4     comp.sys.mac.hardware      1   \n",
       "3             1             comp.graphics      1   \n",
       "4            14                 sci.space      4   \n",
       "...         ...                       ...    ...   \n",
       "11309        13                   sci.med      4   \n",
       "11310         4     comp.sys.mac.hardware      1   \n",
       "11311         3  comp.sys.ibm.pc.hardware      1   \n",
       "11312         1             comp.graphics      1   \n",
       "11313         8           rec.motorcycles      3   \n",
       "\n",
       "                                              preprocess  \\\n",
       "0      i was wondering if anyone out there could enli...   \n",
       "1      a fair number of brave souls who upgraded thei...   \n",
       "2      well folks my mac plus finally gave up the gho...   \n",
       "3       do you have weiteks addressphone number  id l...   \n",
       "4      from article  by  tom a baker   my understandi...   \n",
       "...                                                  ...   \n",
       "11309  dn from  david nye dn a neurology dn consultat...   \n",
       "11310  i have a very old mac 512k and a mac plus both...   \n",
       "11311  i just installed a dx266 cpu in a clone mother...   \n",
       "11312   wouldnt this require a hypersphere  in 3space...   \n",
       "11313  stolen from pasadena between 430 and 630 pm on...   \n",
       "\n",
       "                                                    text  \n",
       "0      wondering anyone could enlighten car saw day 2...  \n",
       "1      fair number brave souls upgraded si clock osci...  \n",
       "2      well folks mac plus finally gave ghost weekend...  \n",
       "3      weiteks addressphone number id like get inform...  \n",
       "4      article tom baker understanding expected error...  \n",
       "...                                                  ...  \n",
       "11309  dn david nye dn neurology dn consultation chea...  \n",
       "11310  old mac 512k mac plus problem screens blank so...  \n",
       "11311  installed dx266 cpu clone motherboard tried mo...  \n",
       "11312  wouldnt require hypersphere 3space 4 points sp...  \n",
       "11313  stolen pasadena 430 630 pm 415 blue white hond...  \n",
       "\n",
       "[11314 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'text': 'wondering anyone could enlighten car saw day 2door sports car looked late 60s early 70s called bricklin doors really small addition front bumper separate rest body know anyone tellme model name engine specs years production car made history whatever info funky looking car please email'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11314/11314 [00:01<00:00, 7174.96 examples/s]\n",
      "Map: 100%|██████████| 7532/7532 [00:00<00:00, 9086.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load model and tokenizer\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\") \n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = new_train.map(preprocess_function, batched=True)\n",
    "tokenized_test = new_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'text': 'little confused models 8889 bonnevilles heard le se lse sse ssei could someone tell differences far features performance also curious know book value prefereably 89 model much less book value usually get words much demand time year heard midspring early summer best time buy'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# label1 = 0, etc\n",
    "id2label = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
    "label2id = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=7, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
       "Args:\n",
       "    predictions (`list` of `int`): Predicted labels.\n",
       "    references (`list` of `int`): Ground truth labels.\n",
       "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
       "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
       "\n",
       "Returns:\n",
       "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1-A simple example\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
       "        >>> print(results)\n",
       "        {'accuracy': 0.5}\n",
       "\n",
       "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
       "        >>> print(results)\n",
       "        {'accuracy': 3.0}\n",
       "\n",
       "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
       "        >>> print(results)\n",
       "        {'accuracy': 0.8778625954198473}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 500/11314 [00:47<18:23,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2045, 'grad_norm': 5.472842693328857, 'learning_rate': 1.911613929644688e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1002/11314 [01:33<15:45, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9352, 'grad_norm': 0.47719475626945496, 'learning_rate': 1.823227859289376e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1502/11314 [02:18<15:06, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9292, 'grad_norm': 0.13571925461292267, 'learning_rate': 1.7348417889340642e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2002/11314 [03:03<14:07, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8531, 'grad_norm': 21.148666381835938, 'learning_rate': 1.6464557185787523e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2502/11314 [03:49<12:57, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7801, 'grad_norm': 0.0958327129483223, 'learning_rate': 1.55806964822344e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3001/11314 [04:36<12:06, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8329, 'grad_norm': 9.007207870483398, 'learning_rate': 1.4696835778681282e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3501/11314 [05:23<10:28, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7411, 'grad_norm': 22.806806564331055, 'learning_rate': 1.3812975075128161e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 4002/11314 [06:08<12:11, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8646, 'grad_norm': 22.182212829589844, 'learning_rate': 1.292911437157504e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4501/11314 [06:54<10:57, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7167, 'grad_norm': 22.938961029052734, 'learning_rate': 1.2045253668021922e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5001/11314 [07:41<12:26,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7798, 'grad_norm': 9.006744384765625, 'learning_rate': 1.11613929644688e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 5500/11314 [08:26<08:14, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7583, 'grad_norm': 52.29185104370117, 'learning_rate': 1.027753226091568e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 50%|█████     | 5657/11314 [09:53<09:24, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8091230392456055, 'eval_accuracy': 0.7971322357939459, 'eval_runtime': 72.8392, 'eval_samples_per_second': 103.406, 'eval_steps_per_second': 51.703, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 6000/11314 [10:25<07:27, 11.88it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5593, 'grad_norm': 0.042891595512628555, 'learning_rate': 9.39367155736256e-06, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 6503/11314 [11:11<06:42, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4982, 'grad_norm': 12.954984664916992, 'learning_rate': 8.50981085380944e-06, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 7002/11314 [11:57<06:56, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5896, 'grad_norm': 123.51172637939453, 'learning_rate': 7.625950150256321e-06, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 7501/11314 [12:46<08:11,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5254, 'grad_norm': 94.30730438232422, 'learning_rate': 6.7420894467032e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 8002/11314 [13:33<06:01,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5198, 'grad_norm': 89.36083221435547, 'learning_rate': 5.85822874315008e-06, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 8502/11314 [14:19<03:35, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4941, 'grad_norm': 0.025787746533751488, 'learning_rate': 4.97436803959696e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 9001/11314 [15:04<03:17, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5378, 'grad_norm': 1.4332557916641235, 'learning_rate': 4.0905073360438394e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 9503/11314 [15:51<02:19, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4753, 'grad_norm': 0.04786647856235504, 'learning_rate': 3.2066466324907197e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 10001/11314 [16:37<01:49, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5677, 'grad_norm': 0.027879901230335236, 'learning_rate': 2.3227859289375996e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 10502/11314 [17:24<01:04, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.487, 'grad_norm': 0.01717495732009411, 'learning_rate': 1.4389252253844795e-06, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 11002/11314 [18:12<00:32,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5201, 'grad_norm': 0.023554306477308273, 'learning_rate': 5.550645218313594e-07, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 11314/11314 [19:58<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9071014523506165, 'eval_accuracy': 0.8088157195963888, 'eval_runtime': 74.2881, 'eval_samples_per_second': 101.389, 'eval_steps_per_second': 50.695, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11314/11314 [20:01<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1201.0206, 'train_samples_per_second': 18.841, 'train_steps_per_second': 9.42, 'train_loss': 0.6891144524409574, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11314, training_loss=0.6891144524409574, metrics={'train_runtime': 1201.0206, 'train_samples_per_second': 18.841, 'train_steps_per_second': 9.42, 'total_flos': 876784157343564.0, 'train_loss': 0.6891144524409574, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3766/3766 [01:12<00:00, 51.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "true_labels = ds_test['label'].values\n",
    "\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "predictions_tensor = torch.tensor(predictions.predictions)\n",
    "\n",
    "\n",
    "predictions = torch.argmax(predictions_tensor, dim=1).cpu().numpy()\n",
    "\n",
    "report = classification_report(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46       319\n",
      "           1       0.89      0.86      0.88      1955\n",
      "           2       0.86      0.73      0.79       390\n",
      "           3       0.78      0.90      0.84      1590\n",
      "           4       0.77      0.80      0.78      1579\n",
      "           5       0.69      0.75      0.71       398\n",
      "           6       0.81      0.69      0.75      1301\n",
      "\n",
      "    accuracy                           0.80      7532\n",
      "   macro avg       0.75      0.74      0.74      7532\n",
      "weighted avg       0.80      0.80      0.80      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
